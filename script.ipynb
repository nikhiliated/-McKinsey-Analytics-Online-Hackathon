{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries  #0.859331533603457\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading Dataframes\n",
    "train= pd.read_csv('train.csv')\n",
    "test= pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                         0\n",
       "Gender                                     0\n",
       "DOB                                       15\n",
       "Lead_Creation_Date                         0\n",
       "City_Code                                814\n",
       "City_Category                            814\n",
       "Employer_Code                           4018\n",
       "Employer_Category1                      4018\n",
       "Employer_Category2                      4298\n",
       "Monthly_Income                             0\n",
       "Customer_Existing_Primary_Bank_Code     9391\n",
       "Primary_Bank_Type                       9391\n",
       "Contacted                                  0\n",
       "Source                                     0\n",
       "Source_Category                            0\n",
       "Existing_EMI                              51\n",
       "Loan_Amount                            27709\n",
       "Loan_Period                            27709\n",
       "Interest_Rate                          47437\n",
       "EMI                                    47437\n",
       "Var1                                       0\n",
       "Approved                                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    68693\n",
       "1     1020\n",
       "Name: Approved, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking imbalance\n",
    "train['Approved'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69713 entries, 0 to 69712\n",
      "Data columns (total 22 columns):\n",
      "ID                                     69713 non-null object\n",
      "Gender                                 69713 non-null object\n",
      "DOB                                    69698 non-null object\n",
      "Lead_Creation_Date                     69713 non-null object\n",
      "City_Code                              68899 non-null object\n",
      "City_Category                          68899 non-null object\n",
      "Employer_Code                          65695 non-null object\n",
      "Employer_Category1                     65695 non-null object\n",
      "Employer_Category2                     65415 non-null float64\n",
      "Monthly_Income                         69713 non-null float64\n",
      "Customer_Existing_Primary_Bank_Code    60322 non-null object\n",
      "Primary_Bank_Type                      60322 non-null object\n",
      "Contacted                              69713 non-null object\n",
      "Source                                 69713 non-null object\n",
      "Source_Category                        69713 non-null object\n",
      "Existing_EMI                           69662 non-null float64\n",
      "Loan_Amount                            42004 non-null float64\n",
      "Loan_Period                            42004 non-null float64\n",
      "Interest_Rate                          22276 non-null float64\n",
      "EMI                                    22276 non-null float64\n",
      "Var1                                   69713 non-null int64\n",
      "Approved                               69713 non-null int64\n",
      "dtypes: float64(7), int64(2), object(13)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre Proessing\n",
    "train_id, test_id = train['ID'], test['ID']\n",
    "target = train['Approved']\n",
    "train = train.drop(['ID', 'Approved'], axis=1)\n",
    "test = test.drop(['ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concating train and test into one\n",
    "data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handling dates\n",
    "import datetime\n",
    "data['DOB'] =  pd.to_datetime(data['DOB'])\n",
    "data['Lead_Creation_Date'] =  pd.to_datetime(data['Lead_Creation_Date'])\n",
    "\n",
    "data['DOB'].fillna(0, inplace=True)\n",
    "data['Lead_Creation_Date'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting key attributes from dates\n",
    "data['DOB_month'] = data['DOB'].dt.month\n",
    "data['DOB_day'] = data['DOB'].dt.day\n",
    "data['DOB_year'] = data['DOB'].dt.year\n",
    "\n",
    "data['Creation_Month'] = data['Lead_Creation_Date'].dt.month\n",
    "data['Creation_Day'] = data['Lead_Creation_Date'].dt.day\n",
    "\n",
    "data['Age']= data['Lead_Creation_Date']-data['DOB']\n",
    "\n",
    "data['Age'] = data['Age'].astype('str')\n",
    "data['Age']= data['Age'].apply(lambda x: x.split(' ', 1)[0])\n",
    "data['Age'] = data['Age'].astype('int64')\n",
    "\n",
    "# Taking care of dob above 2000\n",
    "dob_year = data['DOB_year']\n",
    "dob_year[dob_year>2018] -= 100\n",
    "data['DOB_year'] = dob_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping dob and lead_creation_rate\n",
    "data = data.drop(['DOB', 'Lead_Creation_Date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "from sklearn import preprocessing \n",
    "for i in data.columns: \n",
    "    if data[i].dtype=='object': \n",
    "        encoder = preprocessing.LabelEncoder() \n",
    "        encoder.fit(list(data[i].values)) \n",
    "        data[i] = encoder.transform(list(data[i].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting back into train and test\n",
    "train = data[:len(train)]\n",
    "test  = data[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 1: XGBClassifier\n",
    "train1=train\n",
    "test1=test\n",
    "target1 =target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train1, target1, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "random.seed(3)\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight = float(np.sum(target1 == 0)) / float(np.sum(target1 == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=67.34607843137255, seed=0, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting XGBoost to the Training set\n",
    "classifier = XGBClassifier(scale_pos_weight=weight)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, metrics \n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "\n",
    "param = {\n",
    " 'reg_alpha':[ 0.1, 0.2, 0.3, 0.4]\n",
    " \n",
    "}\n",
    "predictors=data.columns\n",
    "gsearch = GridSearchCV(estimator = XGBClassifier(colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='binary:logistic', reg_lambda=1,\n",
    "       scale_pos_weight=67.34607843137255, seed=0,\n",
    "       subsample=1), \n",
    "param_grid = param, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch.fit(train[predictors],target)\n",
    "gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('classifier.fmap', 'w')\n",
    "    i = 0\n",
    "    for feat in features:\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "        i = i + 1\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting Feature Importances\n",
    "import operator\n",
    "create_feature_map(data.columns)\n",
    "importance = classifier.booster().get_fscore(fmap='classifier.fmap')\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1))\n",
    "\n",
    "df = pd.DataFrame(importance, columns=['feature', 'fscore'])\n",
    "df['fscore'] = df['fscore'] / df['fscore'].sum()\n",
    "plt.figure()\n",
    "df.plot(kind='barh', x='feature', y='fscore', legend=False, figsize=(6, 10))\n",
    "plt.title('XGBoost Feature Importance')\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = classifier.predict_proba(test)\n",
    "predict = predict[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model 2 : XGBoost\n",
    "train2=train\n",
    "test2=test\n",
    "target2 = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(train2, label=target2, missing=np.nan)\n",
    "dtest = xgb.DMatrix(test2, missing=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'booster':'gbtree', 'objective':'multi:softprob', 'max_depth':4, 'num_class': 3, 'seed': 0,\n",
    "          'eta':0.1, 'nthread':4, 'subsample':0.9, 'scale_pos_weight':weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rounds = 350\n",
    "clf_xgb = xgb.train(params, dtrain, num_rounds)\n",
    "xgb_preds = clf_xgb.predict(dtest)\n",
    "xgb_preds = xgb_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensembling\n",
    "ens = predict.copy()\n",
    "ens = predict * 0.6 + xgb_preds * 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final Submission\n",
    "from IPython.display import FileLink\n",
    "sub_3 = pd.DataFrame({'ID': test_id, 'Approved': ens})\n",
    "sub_3 = sub_3[['ID', 'Approved']]\n",
    "filename = 'final.csv'\n",
    "sub_3.to_csv(filename, index=False)\n",
    "FileLink(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
